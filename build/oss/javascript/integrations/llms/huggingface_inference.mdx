---
title: HuggingFaceInference
---

Here's an example of calling a HugggingFaceInference model as an LLM:

```bash npm
npm install @langchain/community @langchain/core @huggingface/inference@4
```

import UnifiedModelParamsTooltip from "/snippets/javascript-integrations/unified-model-params-tooltip.mdx";

<UnifiedModelParamsTooltip />

```typescript
import { HuggingFaceInference } from "@langchain/community/llms/hf";

const model = new HuggingFaceInference({
  model: "gpt2",
  apiKey: "YOUR-API-KEY", // In Node.js defaults to process.env.HUGGINGFACEHUB_API_KEY
});
const res = await model.invoke("1 + 1 =");
console.log({ res });
```

## Related


- [Models guide](/oss/javascript/langchain/models)

---

<CardGroup cols={2}>
  <Card title="View Source" icon="eye" href="https://github.com/langchain-ai/docs/blob/main/src/oss/javascript/integrations/llms/huggingface_inference.mdx">
    See the source of this page on GitHub
  </Card>
  <Card title="Edit Source" icon="pen-to-square" href="https://github.com/langchain-ai/docs/edit/main/src/oss/javascript/integrations/llms/huggingface_inference.mdx">
    Edit the source of this page on GitHub
  </Card>
</CardGroup>
